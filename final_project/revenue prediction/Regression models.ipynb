{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:31:34.600160Z",
     "start_time": "2024-06-01T12:31:34.482422400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# Carica il dataset\n",
    "df = pd.read_csv('../dataset/preprocessed_dataset.csv')\n",
    "df = df.drop('votes', axis=1)\n",
    "df = df.drop('avg_vote', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  converted_budget  dir_oscar_nomination  writer_oscar_nomination  \\\n",
      "0      88.0          175700.3                     0                        0   \n",
      "1      59.0         3013850.0                     0                        0   \n",
      "2      77.0          521727.6                     0                        0   \n",
      "3      50.0         5598468.6                     0                        0   \n",
      "4     300.0        10802441.1                     0                        0   \n",
      "\n",
      "   cast_globe_nomination  BAFTA_act_nom  BAFTA_dir_nom  BAFTA_writer_nom  \\\n",
      "0                      0              0              0                 0   \n",
      "1                      0              0              0                 0   \n",
      "2                      0              0              0                 0   \n",
      "3                      0              0              0                 0   \n",
      "4                      0              0              0                 0   \n",
      "\n",
      "   dir_emmy_nom  writer_emmy_nom  ...  month_published_11  month_published_12  \\\n",
      "0             0                0  ...                   1                   0   \n",
      "1             0                0  ...                   0                   0   \n",
      "2             0                0  ...                   1                   0   \n",
      "3             0                0  ...                   0                   0   \n",
      "4             0                0  ...                   0                   0   \n",
      "\n",
      "   month_published_2  month_published_3  month_published_4  month_published_5  \\\n",
      "0                  0                  0                  0                  0   \n",
      "1                  0                  0                  0                  0   \n",
      "2                  0                  0                  0                  0   \n",
      "3                  0                  0                  1                  0   \n",
      "4                  0                  0                  0                  0   \n",
      "\n",
      "   month_published_6  month_published_7  month_published_8  month_published_9  \n",
      "0                  0                  0                  0                  0  \n",
      "1                  0                  0                  0                  0  \n",
      "2                  0                  0                  0                  0  \n",
      "3                  0                  0                  0                  0  \n",
      "4                  0                  0                  0                  0  \n",
      "\n",
      "[5 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('revenue_with_CPI', axis=1)\n",
    "y = df['revenue_with_CPI']\n",
    "print(X.head())\n",
    "\n",
    "numerical_columns = ['duration','converted_budget',\n",
    "                     'dir_oscar_nomination', 'writer_oscar_nomination',\n",
    "                     'cast_globe_nomination',\n",
    "                     'BAFTA_writer_nom', 'BAFTA_dir_nom', 'BAFTA_act_nom', \n",
    "                     'dir_emmy_nom', 'writer_emmy_nom', 'act_emmy_nom',\n",
    "                     'actors_films_before', 'director_films_before', 'writers_films_before'\n",
    "                     ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:31:39.687653200Z",
     "start_time": "2024-06-01T12:31:39.550637800Z"
    }
   },
   "id": "c06e8f645e77cbe3"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dividere i dati in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funzione per calcolare il Root Mean Squared Error (RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Funzione per calcolare il Mean Absolute Percentage Error (MAPE)\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Definire il trasformatore logaritmico\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "# Creare un ColumnTransformer per applicare trasformazioni solo alle caratteristiche numeriche\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('log_scaler', Pipeline(steps=[\n",
    "            ('log', log_transformer),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Lasciare le altre colonne intatte\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:16:03.958860600Z",
     "start_time": "2024-06-01T12:16:03.916971700Z"
    }
   },
   "id": "92eaa77704566667"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac6f1dd274b39ba4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__bootstrap': True, 'regressor__criterion': 'squared_error', 'regressor__max_depth': 10, 'regressor__max_features': 'sqrt', 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 300, 'regressor__random_state': 42}\n",
      "Test set results:\n",
      "Final RMSE: 210818343.33922222\n",
      "Final MAE: 89102329.1025544\n",
      "Final MSE: 4.4444373888294184e+16\n",
      "Final R2: 0.40265109530598897\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 198143181.8594518\n",
      "Final MAE: 81232480.62071209\n",
      "Final MSE: 3.926072051738779e+16\n",
      "Final R2: 0.5348351978332291\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 300],\n",
    "    'regressor__max_depth': [ 4, 10],\n",
    "    'regressor__min_samples_split': [2, 10],\n",
    "    'regressor__min_samples_leaf': [1, 4],\n",
    "    'regressor__max_features': [ 'sqrt', 4],  \n",
    "    'regressor__bootstrap': [True, False],  # Puoi testare sia True che False\n",
    "    'regressor__criterion': ['squared_error', 'poisson'],# 'absolute_error', 'friedman_mse'], \n",
    "    'regressor__random_state': [42]  \n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T10:35:39.501734600Z",
     "start_time": "2024-06-01T10:29:23.728052400Z"
    }
   },
   "id": "858338721bd64ae6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AdaBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10059aaec034ba22"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__learning_rate': 0.01, 'regressor__loss': 'exponential', 'regressor__n_estimators': 50}\n",
      "Test set results:\n",
      "Final RMSE: 213078427.5505543\n",
      "Final MAE: 85459858.0560362\n",
      "Final MSE: 4.540241628741682e+16\n",
      "Final R2: 0.3897746493647164\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 214334476.40398216\n",
      "Final MAE: 81809219.25231358\n",
      "Final MSE: 4.593926777536918e+16\n",
      "Final R2: 0.4557071259822685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creare la pipeline completa\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', AdaBoostRegressor(random_state=42))\n",
    "])\n",
    "# Definire una griglia dei parametri da esplorare per AdaBoostRegressor\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'regressor__loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:04:19.926972500Z",
     "start_time": "2024-06-01T12:02:10.591299Z"
    }
   },
   "id": "4d92aba84b865a37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GradientBoosting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d4caff3c9b01b49"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__learning_rate': 0.1, 'regressor__max_depth': 3, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 50}\n",
      "Test set results:\n",
      "Final RMSE: 218257105.33626708\n",
      "Final MAE: 83351584.59714966\n",
      "Final MSE: 4.763616402976639e+16\n",
      "Final R2: 0.359752249440512\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 199650305.7017214\n",
      "Final MAE: 77359532.1519939\n",
      "Final MSE: 3.986024456679081e+16\n",
      "Final R2: 0.5277319790904333\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa per GradientBoostingRegressor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per GradientBoostingRegressor\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:55:17.479749700Z",
     "start_time": "2024-06-01T12:39:19.689309500Z"
    }
   },
   "id": "bd5f59b7f2577cf3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ElasticNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cebaccbc11182a5"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.9}\n",
      "Test set results:\n",
      "Final RMSE: 255072458.62690815\n",
      "Final MAE: 119316715.32961605\n",
      "Final MSE: 6.506195914997578e+16\n",
      "Final R2: 0.12554308598954644\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 273842741.7020254\n",
      "Final MAE: 118242345.18430261\n",
      "Final MSE: 7.498984718288222e+16\n",
      "Final R2: 0.11151306013619999\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa per ElasticNet\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', ElasticNet(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per ElasticNet\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 0.5, 1.0],\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T13:42:03.890366700Z",
     "start_time": "2024-06-01T13:41:54.848254900Z"
    }
   },
   "id": "48254aea411c376f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Knneighbors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88528bd14221b7f8"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__C': 10, 'regressor__epsilon': 0.01, 'regressor__kernel': 'linear'}\n",
      "Test set results:\n",
      "Final RMSE: 287543648.06016934\n",
      "Final MAE: 101571450.52714463\n",
      "Final MSE: 8.268134953975051e+16\n",
      "Final R2: -0.111268069842265\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 302904636.78913206\n",
      "Final MAE: 96717567.02796443\n",
      "Final MSE: 9.175121898835603e+16\n",
      "Final R2: -0.08707728912863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Creare la pipeline completa per SVR\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per SVR\n",
    "param_grid = {\n",
    "    'regressor__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'regressor__weights': ['uniform', 'distance'],\n",
    "    'regressor__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'regressor__leaf_size': [20, 30, 40, 50],\n",
    "    'regressor__p': [1, 2]  # Parametro p: 1 = distanza di Manhattan, 2 = distanza euclidea\n",
    "}\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T14:04:23.164749900Z",
     "start_time": "2024-06-01T13:49:32.047335200Z"
    }
   },
   "id": "fbecbb7b98014b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DecisionTree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "825a95458139ee58"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 2}\n",
      "Test set results:\n",
      "Final RMSE: 234341231.2186275\n",
      "Final MAE: 88080157.98294143\n",
      "Final MSE: 5.491581264906225e+16\n",
      "Final R2: 0.26191106620721727\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 192282060.24231523\n",
      "Final MAE: 71758403.94561547\n",
      "Final MSE: 3.697239069102934e+16\n",
      "Final R2: 0.561947550254243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Creare la pipeline completa per MLP\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per MLP\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T16:19:43.954488600Z",
     "start_time": "2024-06-01T16:19:25.132505100Z"
    }
   },
   "id": "e651287ad472a985"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
