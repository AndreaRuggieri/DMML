{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:31:34.600160Z",
     "start_time": "2024-06-01T12:31:34.482422400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# Carica il dataset\n",
    "df = pd.read_csv('../dataset/preprocessed_dataset.csv')\n",
    "df = df.drop('votes', axis=1)\n",
    "df = df.drop('avg_vote', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  converted_budget  dir_oscar_nomination  writer_oscar_nomination  \\\n",
      "0      88.0          175700.3                     0                        0   \n",
      "1      59.0         3013850.0                     0                        0   \n",
      "2      77.0          521727.6                     0                        0   \n",
      "3      50.0         5598468.6                     0                        0   \n",
      "4     300.0        10802441.1                     0                        0   \n",
      "\n",
      "   cast_globe_nomination  BAFTA_act_nom  BAFTA_dir_nom  BAFTA_writer_nom  \\\n",
      "0                      0              0              0                 0   \n",
      "1                      0              0              0                 0   \n",
      "2                      0              0              0                 0   \n",
      "3                      0              0              0                 0   \n",
      "4                      0              0              0                 0   \n",
      "\n",
      "   dir_emmy_nom  writer_emmy_nom  ...  month_published_11  month_published_12  \\\n",
      "0             0                0  ...                   1                   0   \n",
      "1             0                0  ...                   0                   0   \n",
      "2             0                0  ...                   1                   0   \n",
      "3             0                0  ...                   0                   0   \n",
      "4             0                0  ...                   0                   0   \n",
      "\n",
      "   month_published_2  month_published_3  month_published_4  month_published_5  \\\n",
      "0                  0                  0                  0                  0   \n",
      "1                  0                  0                  0                  0   \n",
      "2                  0                  0                  0                  0   \n",
      "3                  0                  0                  1                  0   \n",
      "4                  0                  0                  0                  0   \n",
      "\n",
      "   month_published_6  month_published_7  month_published_8  month_published_9  \n",
      "0                  0                  0                  0                  0  \n",
      "1                  0                  0                  0                  0  \n",
      "2                  0                  0                  0                  0  \n",
      "3                  0                  0                  0                  0  \n",
      "4                  0                  0                  0                  0  \n",
      "\n",
      "[5 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('revenue_with_CPI', axis=1)\n",
    "y = df['revenue_with_CPI']\n",
    "print(X.head())\n",
    "\n",
    "numerical_columns = ['duration','converted_budget',\n",
    "                     'dir_oscar_nomination', 'writer_oscar_nomination',\n",
    "                     'cast_globe_nomination',\n",
    "                     'BAFTA_writer_nom', 'BAFTA_dir_nom', 'BAFTA_act_nom', \n",
    "                     'dir_emmy_nom', 'writer_emmy_nom', 'act_emmy_nom',\n",
    "                     'actors_films_before', 'director_films_before', 'writers_films_before'\n",
    "                     ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:31:39.687653200Z",
     "start_time": "2024-06-01T12:31:39.550637800Z"
    }
   },
   "id": "c06e8f645e77cbe3"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dividere i dati in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funzione per calcolare il Root Mean Squared Error (RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Funzione per calcolare il Mean Absolute Percentage Error (MAPE)\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Definire il trasformatore logaritmico\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "# Creare un ColumnTransformer per applicare trasformazioni solo alle caratteristiche numeriche\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('log_scaler', Pipeline(steps=[\n",
    "            ('log', log_transformer),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Lasciare le altre colonne intatte\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:16:03.958860600Z",
     "start_time": "2024-06-01T12:16:03.916971700Z"
    }
   },
   "id": "92eaa77704566667"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac6f1dd274b39ba4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__bootstrap': True, 'regressor__criterion': 'squared_error', 'regressor__max_depth': 10, 'regressor__max_features': 'sqrt', 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 300, 'regressor__random_state': 42}\n",
      "Test set results:\n",
      "Final RMSE: 210818343.33922222\n",
      "Final MAE: 89102329.1025544\n",
      "Final MSE: 4.4444373888294184e+16\n",
      "Final R2: 0.40265109530598897\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 198143181.8594518\n",
      "Final MAE: 81232480.62071209\n",
      "Final MSE: 3.926072051738779e+16\n",
      "Final R2: 0.5348351978332291\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 300],\n",
    "    'regressor__max_depth': [ 4, 10],\n",
    "    'regressor__min_samples_split': [2, 10],\n",
    "    'regressor__min_samples_leaf': [1, 4],\n",
    "    'regressor__max_features': [ 'sqrt', 4],  \n",
    "    'regressor__bootstrap': [True, False],  # Puoi testare sia True che False\n",
    "    'regressor__criterion': ['squared_error', 'poisson'],# 'absolute_error', 'friedman_mse'], \n",
    "    'regressor__random_state': [42]  \n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T10:35:39.501734600Z",
     "start_time": "2024-06-01T10:29:23.728052400Z"
    }
   },
   "id": "858338721bd64ae6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AdaBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10059aaec034ba22"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__learning_rate': 0.01, 'regressor__loss': 'exponential', 'regressor__n_estimators': 50}\n",
      "Test set results:\n",
      "Final RMSE: 213078427.5505543\n",
      "Final MAE: 85459858.0560362\n",
      "Final MSE: 4.540241628741682e+16\n",
      "Final R2: 0.3897746493647164\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 214334476.40398216\n",
      "Final MAE: 81809219.25231358\n",
      "Final MSE: 4.593926777536918e+16\n",
      "Final R2: 0.4557071259822685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creare la pipeline completa\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', AdaBoostRegressor(random_state=42))\n",
    "])\n",
    "# Definire una griglia dei parametri da esplorare per AdaBoostRegressor\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'regressor__loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:04:19.926972500Z",
     "start_time": "2024-06-01T12:02:10.591299Z"
    }
   },
   "id": "4d92aba84b865a37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GradientBoosting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d4caff3c9b01b49"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__learning_rate': 0.1, 'regressor__max_depth': 3, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 50}\n",
      "Test set results:\n",
      "Final RMSE: 218257105.33626708\n",
      "Final MAE: 83351584.59714966\n",
      "Final MSE: 4.763616402976639e+16\n",
      "Final R2: 0.359752249440512\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 199650305.7017214\n",
      "Final MAE: 77359532.1519939\n",
      "Final MSE: 3.986024456679081e+16\n",
      "Final R2: 0.5277319790904333\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa per GradientBoostingRegressor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per GradientBoostingRegressor\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T12:55:17.479749700Z",
     "start_time": "2024-06-01T12:39:19.689309500Z"
    }
   },
   "id": "bd5f59b7f2577cf3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ElasticNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cebaccbc11182a5"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.9}\n",
      "Test set results:\n",
      "Final RMSE: 255072458.62690815\n",
      "Final MAE: 119316715.32961605\n",
      "Final MSE: 6.506195914997578e+16\n",
      "Final R2: 0.12554308598954644\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 273842741.7020254\n",
      "Final MAE: 118242345.18430261\n",
      "Final MSE: 7.498984718288222e+16\n",
      "Final R2: 0.11151306013619999\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa per ElasticNet\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', ElasticNet(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per ElasticNet\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 0.5, 1.0],\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T13:42:03.890366700Z",
     "start_time": "2024-06-01T13:41:54.848254900Z"
    }
   },
   "id": "48254aea411c376f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88528bd14221b7f8"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__C': 10, 'regressor__epsilon': 0.01, 'regressor__kernel': 'linear'}\n",
      "Test set results:\n",
      "Final RMSE: 287543648.06016934\n",
      "Final MAE: 101571450.52714463\n",
      "Final MSE: 8.268134953975051e+16\n",
      "Final R2: -0.111268069842265\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 302904636.78913206\n",
      "Final MAE: 96717567.02796443\n",
      "Final MSE: 9.175121898835603e+16\n",
      "Final R2: -0.08707728912863\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa per SVR\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per SVR\n",
    "param_grid = {\n",
    "    'regressor__C': [0.1, 1.0, 10],\n",
    "    'regressor__epsilon': [0.01, 0.1, 1.0],\n",
    "    'regressor__kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T14:04:23.164749900Z",
     "start_time": "2024-06-01T13:49:32.047335200Z"
    }
   },
   "id": "fbecbb7b98014b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "825a95458139ee58"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "180 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-9.42976777e+016              nan -9.42976777e+016              nan\n",
      " -9.42976777e+016              nan -9.42849499e+016              nan\n",
      " -9.42849499e+016              nan -9.42849499e+016              nan\n",
      " -8.75409226e+016 -6.50721670e+096 -8.75409226e+016 -4.25586019e+104\n",
      " -8.75409226e+016 -8.15591868e+094 -9.42976782e+016              nan\n",
      " -9.42976782e+016              nan -9.42976782e+016              nan\n",
      " -9.42849482e+016              nan -9.42849482e+016              nan\n",
      " -9.42849482e+016              nan -8.75409277e+016 -6.50721460e+096\n",
      " -8.75409277e+016 -4.25585882e+104 -8.75409277e+016 -8.15591604e+094\n",
      " -9.42976786e+016              nan -9.42976786e+016              nan\n",
      " -9.42976786e+016              nan -9.42849484e+016              nan\n",
      " -9.42849484e+016              nan -9.42849484e+016              nan\n",
      " -8.75409073e+016 -6.50719354e+096 -8.75409073e+016 -4.25584505e+104\n",
      " -8.75409073e+016 -8.15588966e+094 -9.43091347e+016 -7.52355261e+016\n",
      " -9.43091347e+016 -7.97760126e+016 -9.43091347e+016 -7.52015570e+016\n",
      " -9.43089846e+016 -7.16934910e+016 -9.43089846e+016 -7.79022762e+016\n",
      " -9.43089846e+016 -7.16041766e+016 -9.43091366e+016 -8.23079405e+016\n",
      " -9.43091366e+016 -8.33176860e+016 -9.43091366e+016 -8.21828400e+016\n",
      " -9.43091347e+016 -7.59835587e+016 -9.43091347e+016 -8.01609102e+016\n",
      " -9.43091347e+016 -7.59090612e+016 -9.43089846e+016 -7.20978827e+016\n",
      " -9.43089846e+016 -7.78856406e+016 -9.43089846e+016 -7.18505055e+016\n",
      " -9.43091366e+016 -8.22016981e+016 -9.43091366e+016 -8.33360604e+016\n",
      " -9.43091366e+016 -8.22758385e+016 -9.43091347e+016 -7.42309899e+016\n",
      " -9.43091347e+016 -8.04016299e+016 -9.43091347e+016 -7.36201114e+016\n",
      " -9.43089846e+016 -7.21920183e+016 -9.43089846e+016 -7.82923095e+016\n",
      " -9.43089846e+016 -7.15973971e+016 -9.43091366e+016 -8.22850199e+016\n",
      " -9.43091366e+016 -8.33591714e+016 -9.43091366e+016 -8.23618726e+016\n",
      " -9.43091364e+016 -7.17846677e+016 -9.43091364e+016 -7.78199370e+016\n",
      " -9.43091364e+016 -7.17819842e+016 -9.43089877e+016 -7.07591516e+016\n",
      " -9.43089877e+016 -7.59816979e+016 -9.43089877e+016 -7.07308489e+016\n",
      " -9.43091386e+016 -8.44393162e+016 -9.43091386e+016 -8.44224694e+016\n",
      " -9.43091386e+016 -8.44188339e+016 -9.43091364e+016 -7.19618238e+016\n",
      " -9.43091364e+016 -7.77109094e+016 -9.43091364e+016 -7.23580001e+016\n",
      " -9.43089877e+016 -7.08437835e+016 -9.43089877e+016 -7.57496297e+016\n",
      " -9.43089877e+016 -7.07305184e+016 -9.43091386e+016 -8.44393163e+016\n",
      " -9.43091386e+016 -8.44224695e+016 -9.43091386e+016 -8.44188338e+016\n",
      " -9.43091364e+016 -7.27700999e+016 -9.43091364e+016 -7.79619405e+016\n",
      " -9.43091364e+016 -7.31962348e+016 -9.43089877e+016 -7.17096273e+016\n",
      " -9.43089877e+016 -7.59024105e+016 -9.43089877e+016 -7.15991009e+016\n",
      " -9.43091386e+016 -8.44393167e+016 -9.43091386e+016 -8.44224696e+016\n",
      " -9.43091386e+016 -8.44188338e+016]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'regressor__activation': 'logistic', 'regressor__alpha': 0.001, 'regressor__hidden_layer_sizes': (100,), 'regressor__learning_rate': 'adaptive', 'regressor__solver': 'sgd'}\n",
      "Test set results:\n",
      "Final RMSE: 246693641.5472362\n",
      "Final MAE: 112080264.20916313\n",
      "Final MSE: 6.0857752779836264e+16\n",
      "Final R2: 0.18204918227571476\n",
      "\n",
      "Train set results:\n",
      "Final RMSE: 267061197.94797277\n",
      "Final MAE: 111538785.92553411\n",
      "Final MSE: 7.13216834494063e+16\n",
      "Final R2: 0.15497381773085395\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa per MLP\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k=20)),\n",
    "    ('regressor', MLPRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare per MLP\n",
    "param_grid = {\n",
    "    'regressor__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'regressor__activation': ['relu', 'tanh', 'logistic'],\n",
    "    'regressor__solver': ['adam', 'sgd'],\n",
    "    'regressor__alpha': [0.0001, 0.001, 0.01],\n",
    "    'regressor__learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_rmse_test = rmse(y_test, y_pred_test)\n",
    "final_r2_test = r2_score(y_test, y_pred_test)\n",
    "final_mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "final_mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_rmse_train = rmse(y_train, y_pred_train)\n",
    "final_r2_train = r2_score(y_train, y_pred_train)\n",
    "final_mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "final_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_test)\n",
    "print(\"Final MAE:\", final_mae_test)\n",
    "print(\"Final MSE:\", final_mse_test)\n",
    "print(\"Final R2:\", final_r2_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final RMSE:\", final_rmse_train)\n",
    "print(\"Final MAE:\", final_mae_train)\n",
    "print(\"Final MSE:\", final_mse_train)\n",
    "print(\"Final R2:\", final_r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T15:00:17.551467200Z",
     "start_time": "2024-06-01T14:05:11.979281300Z"
    }
   },
   "id": "e651287ad472a985"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
