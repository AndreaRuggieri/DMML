{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T17:09:18.412497800Z",
     "start_time": "2024-06-02T17:09:18.240641900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Carica il dataset\n",
    "df = pd.read_csv('../dataset/discretized_dataset.csv')\n",
    "df = df.drop('votes', axis=1)\n",
    "df = df.drop('avg_vote', axis=1)\n",
    "\n",
    "def multi_value_one_hot(df, column):\n",
    "    s = df[column].str.get_dummies(sep=', ')\n",
    "    return df.join(s.add_prefix(column + '_'))\n",
    "\n",
    "df = multi_value_one_hot(df, 'genre')\n",
    "\n",
    "df.drop(columns=['genre'], inplace=True)\n",
    "df['month_published'] = df['month_published'].astype(str)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T17:09:18.684494400Z",
     "start_time": "2024-06-02T17:09:18.279290400Z"
    }
   },
   "id": "9b76f4305d5dd9bd"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  converted_budget  dir_oscar_nomination  writer_oscar_nomination  \\\n",
      "0      88.0          175700.3                     0                        0   \n",
      "1      59.0         3013850.0                     0                        0   \n",
      "2      77.0          521727.6                     0                        0   \n",
      "3      50.0         5598468.6                     0                        0   \n",
      "4     300.0        10802441.1                     0                        0   \n",
      "\n",
      "   cast_globe_nomination  BAFTA_act_nom  BAFTA_dir_nom  BAFTA_writer_nom  \\\n",
      "0                      0              0              0                 0   \n",
      "1                      0              0              0                 0   \n",
      "2                      0              0              0                 0   \n",
      "3                      0              0              0                 0   \n",
      "4                      0              0              0                 0   \n",
      "\n",
      "   dir_emmy_nom  writer_emmy_nom  ...  genre_Horror  genre_Music  \\\n",
      "0             0                0  ...             0            0   \n",
      "1             0                0  ...             0            0   \n",
      "2             0                0  ...             0            0   \n",
      "3             0                0  ...             0            0   \n",
      "4             0                0  ...             0            0   \n",
      "\n",
      "   genre_Musical  genre_Mystery genre_Romance genre_Sci-Fi genre_Sport  \\\n",
      "0              0              0             0            0           0   \n",
      "1              0              0             0            0           0   \n",
      "2              0              0             0            0           0   \n",
      "3              0              0             0            0           0   \n",
      "4              0              0             0            0           0   \n",
      "\n",
      "   genre_Thriller  genre_War  genre_Western  \n",
      "0               0          0              0  \n",
      "1               0          0              0  \n",
      "2               0          1              0  \n",
      "3               0          0              0  \n",
      "4               0          0              0  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('revenue_cluster', axis=1)\n",
    "y = df['revenue_cluster']\n",
    "print(X.head())\n",
    "\n",
    "numerical_features = ['duration','converted_budget',\n",
    "                     'dir_oscar_nomination', 'writer_oscar_nomination',\n",
    "                     'cast_globe_nomination',\n",
    "                     'BAFTA_writer_nom', 'BAFTA_dir_nom', 'BAFTA_act_nom', \n",
    "                     'dir_emmy_nom', 'writer_emmy_nom', 'act_emmy_nom',\n",
    "                     'actors_films_before', 'director_films_before', 'writers_films_before'\n",
    "                     ]\n",
    "\n",
    "categorical_features_no_genre = ['language', 'production_company', 'month_published']\n",
    "categorical_features =categorical_features_no_genre + [col for col in df.columns if col.startswith('genre_')]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T17:09:18.731498Z",
     "start_time": "2024-06-02T17:09:18.705491300Z"
    }
   },
   "id": "fcdaa2c3378126ef"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "\n",
    "# Dividere i dati in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Creare il trasformatore logaritmico\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DropOtherColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, prefix='Other'):\n",
    "        self.prefix = prefix\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Trova i nomi delle colonne che iniziano con il prefisso specificato\n",
    "        other_columns = [col for col in X.columns if col.startswith(self.prefix)]\n",
    "        # Rimuovi le colonne trovate\n",
    "        return X.drop(columns=other_columns, errors='ignore')\n",
    "\n",
    "# Definire le colonne da eliminare dopo l'encoding\n",
    "columns_to_drop_after_encoding = ['language_Other', 'production_company_Other']\n",
    "\n",
    "# Creare un ColumnTransformer per applicare trasformazioni\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('log', log_transformer),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),  # Applica solo l'encoding delle colonne categoriche\n",
    "        ('drop_other', DropOtherColumns(), [])  # Applica il trasformatore per l'eliminazione delle colonne \"Other\" dopo l'encoding\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T17:09:18.794491Z",
     "start_time": "2024-06-02T17:09:18.743490700Z"
    }
   },
   "id": "86f6ce63bce24702"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7c814571521de0c"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "Test set results:\n",
      "Final Accuracy: 0.4892538034291234\n",
      "Final F1 Score: 0.4841779213204224\n",
      "Confusion Matrix:\n",
      " [[484 315 437 176]\n",
      " [225 402  86 298]\n",
      " [231  43 951  51]\n",
      " [ 66 163  24 189]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.34      0.40      1412\n",
      "           1       0.44      0.40      0.42      1011\n",
      "           2       0.63      0.75      0.69      1276\n",
      "           3       0.26      0.43      0.33       442\n",
      "\n",
      "    accuracy                           0.49      4141\n",
      "   macro avg       0.45      0.48      0.46      4141\n",
      "weighted avg       0.49      0.49      0.48      4141\n",
      "\n",
      "\n",
      "Train set results:\n",
      "Final Accuracy: 0.5638734605167833\n",
      "Final F1 Score: 0.5626841396337882\n",
      "Confusion Matrix:\n",
      " [[2410 1069 1386  785]\n",
      " [ 692 1984  298 1069]\n",
      " [ 626  221 4089  169]\n",
      " [ 243  568   98  857]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.43      0.50      5650\n",
      "           1       0.52      0.49      0.50      4043\n",
      "           2       0.70      0.80      0.75      5105\n",
      "           3       0.30      0.49      0.37      1766\n",
      "\n",
      "    accuracy                           0.56     16564\n",
      "   macro avg       0.53      0.55      0.53     16564\n",
      "weighted avg       0.58      0.56      0.56     16564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=[X.columns.get_loc(col) for col in categorical_features], random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [ 100, 300],\n",
    "    'classifier__max_depth': [None, 10, 4],\n",
    "    'classifier__min_samples_split': [2, 10],\n",
    "    'classifier__min_samples_leaf': [1],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__bootstrap': [True],# False],\n",
    "    'classifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/RandomForestClassifier.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T18:35:08.651127800Z",
     "start_time": "2024-06-02T17:09:18.809500100Z"
    }
   },
   "id": "922310789dd5901b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "934ba9deebf50fcc"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=categorical_features, random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['liblinear']  \n",
    "}\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T18:48:02.205972200Z",
     "start_time": "2024-06-02T18:35:08.707226300Z"
    }
   },
   "id": "aa539abb487dc84d"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results:\n",
      "Final Accuracy: 0.47162521130161794\n",
      "Final F1 Score: 0.452990705939036\n",
      "Confusion Matrix:\n",
      " [[ 342  262  550  258]\n",
      " [ 170  357  133  351]\n",
      " [ 123   38 1033   82]\n",
      " [  52  133   36  221]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.24      0.33      1412\n",
      "           1       0.45      0.35      0.40      1011\n",
      "           2       0.59      0.81      0.68      1276\n",
      "           3       0.24      0.50      0.33       442\n",
      "\n",
      "    accuracy                           0.47      4141\n",
      "   macro avg       0.45      0.48      0.43      4141\n",
      "weighted avg       0.49      0.47      0.45      4141\n",
      "\n",
      "\n",
      "Train set results:\n",
      "Final Accuracy: 0.4757908717701038\n",
      "Final F1 Score: 0.46055253961944304\n",
      "Confusion Matrix:\n",
      " [[1432 1010 2093 1115]\n",
      " [ 685 1457  456 1445]\n",
      " [ 501  185 4105  314]\n",
      " [ 209  529  141  887]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.25      0.34      5650\n",
      "           1       0.46      0.36      0.40      4043\n",
      "           2       0.60      0.80      0.69      5105\n",
      "           3       0.24      0.50      0.32      1766\n",
      "\n",
      "    accuracy                           0.48     16564\n",
      "   macro avg       0.45      0.48      0.44     16564\n",
      "weighted avg       0.50      0.48      0.46     16564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/LogisticRegression.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T18:48:16.531645100Z",
     "start_time": "2024-06-02T18:48:02.256076100Z"
    }
   },
   "id": "e66d4f5edd6dab58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AdaBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "486cc3c0ec82a295"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__algorithm': 'SAMME.R', 'classifier__learning_rate': 0.1, 'classifier__n_estimators': 100}\n",
      "Test set results:\n",
      "Final Accuracy: 0.5013281815986477\n",
      "Final F1 Score: 0.5009509489778415\n",
      "Confusion Matrix:\n",
      " [[547 348 368 149]\n",
      " [236 474  65 236]\n",
      " [299  50 890  37]\n",
      " [ 63 193  21 165]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43      1412\n",
      "           1       0.45      0.47      0.46      1011\n",
      "           2       0.66      0.70      0.68      1276\n",
      "           3       0.28      0.37      0.32       442\n",
      "\n",
      "    accuracy                           0.50      4141\n",
      "   macro avg       0.47      0.48      0.47      4141\n",
      "weighted avg       0.51      0.50      0.50      4141\n",
      "\n",
      "\n",
      "Train set results:\n",
      "Final Accuracy: 0.5078483458101908\n",
      "Final F1 Score: 0.5080638715997898\n",
      "Confusion Matrix:\n",
      " [[2163 1354 1443  690]\n",
      " [ 895 1946  233  969]\n",
      " [1111  217 3601  176]\n",
      " [ 240  747   77  702]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.38      0.43      5650\n",
      "           1       0.46      0.48      0.47      4043\n",
      "           2       0.67      0.71      0.69      5105\n",
      "           3       0.28      0.40      0.33      1766\n",
      "\n",
      "    accuracy                           0.51     16564\n",
      "   macro avg       0.47      0.49      0.48     16564\n",
      "weighted avg       0.52      0.51      0.51     16564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=[X.columns.get_loc(col) for col in categorical_features], random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 150],  # Numero di stimatori\n",
    "    'classifier__learning_rate': [0.01, 0.1, 1.0],  # Tasso di apprendimento\n",
    "    'classifier__algorithm': ['SAMME', 'SAMME.R']  # Algoritmo per calcolare i pesi degli stimatori\n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/AdaBoostClassifier.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T19:07:45.639454600Z",
     "start_time": "2024-06-02T18:48:16.543623800Z"
    }
   },
   "id": "26c9da3ed08fbc93"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bdefd42af45cdf8"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 1920 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n562 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\imblearn\\pipeline.py\", line 326, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n\n--------------------------------------------------------------------------------\n398 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\imblearn\\pipeline.py\", line 326, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n\n--------------------------------------------------------------------------------\n960 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\imblearn\\pipeline.py\", line 326, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 431, in fit\n    self._check_params()\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 276, in _check_params\n    self._loss = loss_class(self.n_classes_)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 889, in __init__\n    raise ValueError(\nValueError: ExponentialLoss requires 2 classes; got 4 class(es)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[85], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(pipeline, param_grid, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Eseguire la ricerca della griglia sui dati di addestramento\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Ottenere i migliori parametri trovati\u001B[39;00m\n\u001B[0;32m     29\u001B[0m best_params \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    894\u001B[0m     )\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1417\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1418\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1419\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    870\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    873\u001B[0m     )\n\u001B[1;32m--> 875\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    408\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    409\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    412\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    413\u001B[0m     )\n\u001B[1;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    417\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    418\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    419\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    423\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    424\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 1920 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n562 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\imblearn\\pipeline.py\", line 326, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n\n--------------------------------------------------------------------------------\n398 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\imblearn\\pipeline.py\", line 326, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n\n--------------------------------------------------------------------------------\n960 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\imblearn\\pipeline.py\", line 326, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 431, in fit\n    self._check_params()\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 276, in _check_params\n    self._loss = loss_class(self.n_classes_)\n  File \"C:\\Users\\BOLO\\miniconda3\\envs\\Business\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 889, in __init__\n    raise ValueError(\nValueError: ExponentialLoss requires 2 classes; got 4 class(es)\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=[X.columns.get_loc(col) for col in categorical_features], random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid= {\n",
    "    'classifier__n_estimators': [100, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'classifier__max_depth': [3, 7],\n",
    "    'classifier__min_samples_split': [2,  10],\n",
    "    'classifier__min_samples_leaf': [1],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__subsample': [0.8, 1.0],  # Frazione di campioni da utilizzare per il fitting di ciascun albero\n",
    "    'classifier__loss': ['deviance', 'exponential']  # Funzione di perdita da ottimizzare\n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/GradientBoostingClassifier.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T22:20:34.277319800Z",
     "start_time": "2024-06-02T19:07:45.682447700Z"
    }
   },
   "id": "b8d2bf9c77aeb60c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83de6399aca6a332"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 0.1, 'classifier__degree': 2, 'classifier__gamma': 'auto', 'classifier__kernel': 'poly'}\n",
      "Test set results:\n",
      "Final Accuracy: 0.496015455204057\n",
      "Final F1 Score: 0.4924466216601493\n",
      "Confusion Matrix:\n",
      " [[551 254 437 170]\n",
      " [285 384  80 262]\n",
      " [255  32 932  57]\n",
      " [ 81 149  25 187]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.39      0.43      1412\n",
      "           1       0.47      0.38      0.42      1011\n",
      "           2       0.63      0.73      0.68      1276\n",
      "           3       0.28      0.42      0.33       442\n",
      "\n",
      "    accuracy                           0.50      4141\n",
      "   macro avg       0.46      0.48      0.46      4141\n",
      "weighted avg       0.50      0.50      0.49      4141\n",
      "\n",
      "\n",
      "Train set results:\n",
      "Final Accuracy: 0.5040449166867906\n",
      "Final F1 Score: 0.5012148375183663\n",
      "Confusion Matrix:\n",
      " [[2222 1060 1624  744]\n",
      " [1074 1600  310 1059]\n",
      " [ 986  154 3796  169]\n",
      " [ 320  609  106  731]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43      5650\n",
      "           1       0.47      0.40      0.43      4043\n",
      "           2       0.65      0.74      0.69      5105\n",
      "           3       0.27      0.41      0.33      1766\n",
      "\n",
      "    accuracy                           0.50     16564\n",
      "   macro avg       0.47      0.49      0.47     16564\n",
      "weighted avg       0.51      0.50      0.50     16564\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=[X.columns.get_loc(col) for col in categorical_features], random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Parametro di regolarizzazione\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Tipo di kernel da utilizzare\n",
    "    'classifier__gamma': ['scale', 'auto'],  # Coefficiente del kernel per 'rbf', 'poly' e 'sigmoid'\n",
    "    'classifier__degree': [2, 3, 4],  # Grado del polinomio per 'poly'\n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/SVCclassifier.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T09:28:09.345918100Z",
     "start_time": "2024-06-03T06:49:26.352977800Z"
    }
   },
   "id": "d42fc7c6220451e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNNeighbors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d8f0e34d59b3f8c"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__algorithm': 'ball_tree', 'classifier__leaf_size': 20, 'classifier__n_neighbors': 9, 'classifier__p': 1, 'classifier__weights': 'uniform'}\n",
      "Test set results:\n",
      "Final Accuracy: 0.4494083554696933\n",
      "Final F1 Score: 0.45250556780433354\n",
      "Confusion Matrix:\n",
      " [[618 281 359 154]\n",
      " [336 374  80 221]\n",
      " [402  97 732  45]\n",
      " [ 99 173  33 137]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.44      0.43      1412\n",
      "           1       0.40      0.37      0.39      1011\n",
      "           2       0.61      0.57      0.59      1276\n",
      "           3       0.25      0.31      0.27       442\n",
      "\n",
      "    accuracy                           0.45      4141\n",
      "   macro avg       0.42      0.42      0.42      4141\n",
      "weighted avg       0.46      0.45      0.45      4141\n",
      "\n",
      "\n",
      "Train set results:\n",
      "Final Accuracy: 0.5801738710456411\n",
      "Final F1 Score: 0.5821419779403567\n",
      "Confusion Matrix:\n",
      " [[3201  913 1036  500]\n",
      " [ 981 2105  295  662]\n",
      " [1174  257 3536  138]\n",
      " [ 386  533   79  768]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.56      5650\n",
      "           1       0.55      0.52      0.54      4043\n",
      "           2       0.71      0.69      0.70      5105\n",
      "           3       0.37      0.43      0.40      1766\n",
      "\n",
      "    accuracy                           0.58     16564\n",
      "   macro avg       0.55      0.55      0.55     16564\n",
      "weighted avg       0.59      0.58      0.58     16564\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=[X.columns.get_loc(col) for col in categorical_features], random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 9],  # Numero di vicini da considerare\n",
    "    'classifier__weights': ['uniform', 'distance'],  # Pesi utilizzati nella previsione\n",
    "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algoritmo per calcolare i vicini\n",
    "    'classifier__leaf_size': [10, 20, 30],  # Dimensione delle foglie per gli alberi di ricerca\n",
    "    'classifier__p': [1, 2],  # Parametro di potenza per la distanza di Minkowski\n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/KNNClassifier.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:56:17.947428500Z",
     "start_time": "2024-06-03T09:29:01.716465800Z"
    }
   },
   "id": "1e2facbc66484f19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GaussianNB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a40c0511d4ff772"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__var_smoothing': 1e-09}\n",
      "Test set results:\n",
      "Final Accuracy: 0.29630524028012556\n",
      "Final F1 Score: 0.3048312633120409\n",
      "Confusion Matrix:\n",
      " [[253 136 333 690]\n",
      " [ 98 145 112 656]\n",
      " [140  85 527 524]\n",
      " [ 44  63  33 302]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.18      0.26      1412\n",
      "           1       0.34      0.14      0.20      1011\n",
      "           2       0.52      0.41      0.46      1276\n",
      "           3       0.14      0.68      0.23       442\n",
      "\n",
      "    accuracy                           0.30      4141\n",
      "   macro avg       0.37      0.35      0.29      4141\n",
      "weighted avg       0.42      0.30      0.30      4141\n",
      "\n",
      "\n",
      "Train set results:\n",
      "Final Accuracy: 0.3007123883120019\n",
      "Final F1 Score: 0.30600291860913253\n",
      "Confusion Matrix:\n",
      " [[ 961  545 1381 2763]\n",
      " [ 437  572  424 2610]\n",
      " [ 555  332 2219 1999]\n",
      " [ 152  238  147 1229]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.17      0.25      5650\n",
      "           1       0.34      0.14      0.20      4043\n",
      "           2       0.53      0.43      0.48      5105\n",
      "           3       0.14      0.70      0.24      1766\n",
      "\n",
      "    accuracy                           0.30     16564\n",
      "   macro avg       0.37      0.36      0.29     16564\n",
      "weighted avg       0.42      0.30      0.31     16564\n"
     ]
    }
   ],
   "source": [
    "# Creare la pipeline completa con SMOTENC e RandomForestClassifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('smote', SMOTENC(categorical_features=[X.columns.get_loc(col) for col in categorical_features], random_state=42)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "# Definire una griglia dei parametri da esplorare\n",
    "param_grid = {\n",
    "    'classifier__var_smoothing': [1e-9, 1e-8, 1e-7]  # Parametro di smoothing della varianza\n",
    "}\n",
    "\n",
    "\n",
    "# Creare GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Eseguire la ricerca della griglia sui dati di addestramento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Ottenere i migliori parametri trovati\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Addestrare un modello con i migliori parametri trovati sull'intero set di addestramento\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Valutare il modello finale sul set di test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "final_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "final_f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "final_confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "final_classification_report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Valutare il modello sul set di addestramento\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "final_accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "final_f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "final_confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "final_classification_report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Test set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_test)\n",
    "print(\"Final F1 Score:\", final_f1_test)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_test)\n",
    "print(\"Classification Report:\\n\", final_classification_report_test)\n",
    "\n",
    "print(\"\\nTrain set results:\")\n",
    "print(\"Final Accuracy:\", final_accuracy_train)\n",
    "print(\"Final F1 Score:\", final_f1_train)\n",
    "print(\"Confusion Matrix:\\n\", final_confusion_matrix_train)\n",
    "print(\"Classification Report:\\n\", final_classification_report_train)\n",
    "\n",
    "# Specifica il percorso del file dove vuoi salvare il modello\n",
    "file_path = \"../models/classification/GaussianNBClassifier.pkl\"\n",
    "\n",
    "# Crea il percorso della directory se non esiste già\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Salva il miglior modello utilizzando pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T12:28:31.161339100Z",
     "start_time": "2024-06-03T12:23:59.399095300Z"
    }
   },
   "id": "284d4297551b82a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
